{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 06:10:43.351028: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-29 06:10:43.351060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-29 06:10:43.351944: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-29 06:10:43.358157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-29 06:10:44.059985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa el resto de bibliotecas a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 17:50:44.101902: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 17:50:44.101973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 17:50:44.161601: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 17:50:44.287074: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 17:50:45.363248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from tensorflow import keras as kr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import glob\n",
    "from nombreCarpetas import ver_carpetas\n",
    "import pandas as pd\n",
    "import os\n",
    "import psutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para buscar archivos que terminan en \".fastq\", \n",
    "buscara en la direccion \"path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_archivos(path):\n",
    "    \n",
    "    fastq_files = glob.glob(f'{path}/*.fastq',recursive=True)  # This pattern assumes the files are in subdirectories, adjust it as needed\n",
    "\n",
    "    return fastq_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esta celda esta encargada de obtener los nombres de todos los archivos desde una carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders inside the directory\n",
      "numero carpetas:301\n",
      "ejemplo ../tutorialM/datos/sets3/Folder_1\n",
      "['../tutorialM/datos/sets3/Folder_1/stability.trim.contigs.good.fasta']\n",
      "largo de paths: 301\n"
     ]
    }
   ],
   "source": [
    "vc= ver_carpetas()\n",
    "folders_path=\"../tutorialM/datos/sets3\"\n",
    "#folders_path=\"test\"\n",
    "\n",
    "nombres=vc.ver_carpetas(folders_path)\n",
    "#print(f\"numero carpetas:{len(nombres)}\")\n",
    "paths=[]\n",
    "for nombre in nombres:\n",
    "    paths.append(folders_path+\"/\"+nombre)\n",
    "#print(f\"ejemplo {paths[0]}\")\n",
    "#print(buscar_archivos_fasta(paths[0]))\n",
    "#print(f\"largo de paths: {len(paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que devuelve el numero de veces que una \"letra\" (nucleotido) esta presente en una secuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contar_letras(sequence,largo):\n",
    "    possible_letters = ['A', 'C', 'G', 'T', 'N']\n",
    "\n",
    "    letter_counts=[]\n",
    "    for letter in possible_letters:\n",
    "        letter_counts.append(sequence.count(letter))\n",
    "    letter_counts.append(largo)\n",
    "    return letter_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_paired_fastq_files(file1, file2):\n",
    "    sequences_r1 = [] #Lectura de fragmento de secuencia  al derecho\n",
    "    sequences_r2 = [] #Lectura de fragmento de secuencia de reves\n",
    "    qualities_f = []  #calidades de fragmento al derecho\n",
    "    qualities_r= []   #cualidades de fragmento de reves\n",
    "    ids=[]            #id del fragmento de la secuencia\n",
    "    attr_fr=[]        #atributos del fragmento al derecho\n",
    "    attr_rv=[]        #fragmento del fragmento de reves\n",
    "\n",
    "    #se abren los archivos que contienen las lecturas al derecho y de reves\n",
    "    with open(file1, \"r\") as handle1, open(file2, \"r\") as handle2:\n",
    "        \n",
    "        #se almacenan los fragmentos al derecho (record1) y de reves (record2)\n",
    "        #una vez terminado, se vuelve a empezar desde el siguiente fragmento hasta que se terminen\n",
    "        for record1, record2 in zip(SeqIO.parse(handle1, \"fastq\"), SeqIO.parse(handle2, \"fastq\")):\n",
    "            \n",
    "            #se corrobora que ambas lecturas corresponden al mismo fragmento, si no, se saltan ambos fragmentos\n",
    "            assert record1.id.split()[0] == record2.id.split()[0], \"Mismatch in paired reads\"\n",
    "            \n",
    "            #Obtiene el Id de la lectura al derecho\n",
    "            R1_id_mod= record1.id.split()[0].replace(\":\", \"_\")\n",
    "            \n",
    "            #se adjunta los fragmentos por separado\n",
    "            seq1 = str(record1.seq)\n",
    "            seq2 = str(record2.seq)\n",
    "            \n",
    "            #se almacena el largo de ambos fragmentos\n",
    "            l1=len(seq1)\n",
    "            l2=len(seq2)\n",
    "            #se obtiene el numero de bases (nucleotidos) que contiene cada fragmento\n",
    "            car_fr=contar_letras(seq1,l1)\n",
    "            car_rv=contar_letras(seq2,l2)\n",
    "\n",
    "            #se almacena en atributos\n",
    "            attr_fr.append(car_fr)\n",
    "            attr_rv.append(car_rv)\n",
    "            \n",
    "            #si el tamaño de ambos fragmentos no coincide, se rellena el menor con \"N\" \n",
    "            #(base ideterminada)\n",
    "            max_len = max(len(seq1), len(seq2))\n",
    "            if len(seq1) < max_len:\n",
    "                seq1 += 'N' * (max_len - len(seq1))\n",
    "            else:\n",
    "                seq2 += 'N' * (max_len - len(seq2))\n",
    "            \n",
    "            #se almacenan ambas secuencias\n",
    "            sequences_r1.append(seq1)\n",
    "            sequences_r2.append(seq2)\n",
    "\n",
    "            #se almacenan las calidades de los fragmentos\n",
    "            #se rellena con 0 para las N añadidas anteriormente\n",
    "            len_diff1 = len(seq1) - len(record1.letter_annotations[\"phred_quality\"])\n",
    "            if len_diff1 > 0:\n",
    "                record1.letter_annotations[\"phred_quality\"].extend([0] * len_diff1)\n",
    "            len_diff2 = len(seq2) - len(record2.letter_annotations[\"phred_quality\"])\n",
    "            if len_diff2 > 0:\n",
    "                record2.letter_annotations[\"phred_quality\"].extend([0] * len_diff2)\n",
    "            \n",
    "            #adjunta las calidades por separado como listas\n",
    "            qualities_f.append(record1.letter_annotations[\"phred_quality\"])\n",
    "            qualities_r.append(record2.letter_annotations[\"phred_quality\"])\n",
    "            \n",
    "            #adjunta el id\n",
    "            ids.append(R1_id_mod)\n",
    "    \n",
    "    #al final se retornan todos los datos juntos\n",
    "    #se ve muy feo y es poco eficaz pero funciona\n",
    "    return np.array(sequences_r1),np.array(sequences_r2),qualities_f,qualities_r,ids,attr_fr,attr_rv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda contiene una funcion que revisa si el los \"ids\" se encuentran presentes en el archivo FASTA \n",
    "\"file1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ver_si_contig_existe(file1,ids):\n",
    "    existe = [[] for _ in range(len(ids))]  #se crea una lista existe del largo de ids\n",
    "    id1=[]\n",
    "\n",
    "    #se abre el archivo fasta y se obtienen solo los ids de todos los fragmentos\n",
    "    for record3 in SeqIO.parse(file1, \"fasta\"):\n",
    "        id1.append(record3.id.split()[0])\n",
    "        \n",
    "    #itera sobre cada ids[i] y compara con cada elemento en id1\n",
    "    #si encuentra una coincidencia (ids[i] == id1[j]), establece existe[i] a 1 (posiblemente indicando verdadero)\n",
    "    #rompe el bucle interno con break para pasar al siguiente ids[i]\n",
    "    for i in range(0,len(ids)):\n",
    "        for j in range(len(id1)):\n",
    "            if(ids[i]==id1[j]):\n",
    "                existe[i]=1\n",
    "                break\n",
    "\n",
    "    #recorre existe y convierte las listas vacías en 0\n",
    "    for i in range(len(existe)):\n",
    "        if isinstance(existe[i], list) and len(existe[i]) == 0:\n",
    "            existe[i] = 0\n",
    "    #retorna el resultado\n",
    "    return existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence_with_quality(sequence, quality_scores):\n",
    "    mapping = {\n",
    "            'A': [1, 0, 0, 0],\n",
    "            'C': [0, 1, 0, 0],\n",
    "            'G': [0, 0, 1, 0],\n",
    "            'T': [0, 0, 0, 1],\n",
    "            'M': [0.5, 0.5, 0, 0],\n",
    "            'R': [0.5, 0, 0.5, 0],\n",
    "            'W': [0.5, 0, 0, 0.5],\n",
    "            'S': [0, 0.5, 0.5, 0],\n",
    "            'Y': [0, 0.5, 0, 0.5],\n",
    "            'K': [0, 0, 0.5, 0.5],\n",
    "            'V': [0.33, 0.33, 0, 0.33],\n",
    "            'H': [0.33, 0.33, 0.33, 0],\n",
    "            'D': [0.33, 0, 0.33, 0.33],\n",
    "            'B': [0, 0.33, 0.33, 0.33],\n",
    "            'N': [0.25, 0.25, 0.25, 0.25],\n",
    "        }\n",
    "\n",
    "    encoded_sequence = []\n",
    "    for i, base in enumerate(sequence):\n",
    "        base_encoding =  mapping.get(base)\n",
    "        if(quality_scores[i]):\n",
    "            quality = quality_scores[i]\n",
    "\n",
    "        else:\n",
    "                quality=0\n",
    "        normalized_quality = 1.0 if quality >= 50 else (quality - 30) / 20 if quality > 30 else 0.0\n",
    "\n",
    "        encoded_sequence.append(base_encoding + [normalized_quality])\n",
    "        \n",
    "    return np.array(encoded_sequence)\n",
    "\n",
    "def encode_fastq(sequences,quality,max_sequence_length=253):\n",
    "    encoded_sequences = []\n",
    "    for qual,seq in zip(quality,sequences):\n",
    "        if len(seq) < max_sequence_length:\n",
    "            seq += 'N' * (max_sequence_length - len(seq))\n",
    "            qual.extend([0] * len(seq))# Pad sequence with 'N' to reach max length\n",
    "        encoded_seq = encode_sequence_with_quality(seq[:max_sequence_length],qual)  # Truncate or pad to fixed length\n",
    "        encoded_sequences.append(encoded_seq)\n",
    "    return np.array(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_sequence(sequence):\n",
    "    mapping = {\n",
    "        'A': [1, 0, 0, 0],\n",
    "        'C': [0, 1, 0, 0],\n",
    "        'G': [0, 0, 1, 0],\n",
    "        'T': [0, 0, 0, 1],\n",
    "        'M': [0.5, 0.5, 0, 0],\n",
    "        'R': [0.5, 0, 0.5, 0],\n",
    "        'W': [0.5, 0, 0, 0.5],\n",
    "        'S': [0, 0.5, 0.5, 0],\n",
    "        'Y': [0, 0.5, 0, 0.5],\n",
    "        'K': [0, 0, 0.5, 0.5],\n",
    "        'V': [0.33, 0.33, 0, 0.33],\n",
    "        'H': [0.33, 0.33, 0.33, 0],\n",
    "        'D': [0.33, 0, 0.33, 0.33],\n",
    "        'B': [0, 0.33, 0.33, 0.33],\n",
    "        'N': [0.25, 0.25, 0.25, 0.25],\n",
    "        '0': [0, 0, 0, 0]\n",
    "    }\n",
    "\n",
    "    return np.array(mapping[base] for base in sequence)\n",
    "\n",
    "def encode_fastq_sequences(sequences):\n",
    "    encoded_sequences = []\n",
    "    for seq in sequences: # Pad sequence with 'N' to reach max length\n",
    "        encoded_seq = one_hot_encode_sequence(seq)  # Truncate or pad to fixed length\n",
    "        encoded_sequences.append(encoded_seq)\n",
    "    return np.array(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence_with_quality(sequence, quality_scores):\n",
    "    mapping = {\n",
    "            'A': [1, 0, 0, 0],\n",
    "            'C': [0, 1, 0, 0],\n",
    "            'G': [0, 0, 1, 0],\n",
    "            'T': [0, 0, 0, 1],\n",
    "            'M': [0.5, 0.5, 0, 0],\n",
    "            'R': [0.5, 0, 0.5, 0],\n",
    "            'W': [0.5, 0, 0, 0.5],\n",
    "            'S': [0, 0.5, 0.5, 0],\n",
    "            'Y': [0, 0.5, 0, 0.5],\n",
    "            'K': [0, 0, 0.5, 0.5],\n",
    "            'V': [0.33, 0.33, 0, 0.33],\n",
    "            'H': [0.33, 0.33, 0.33, 0],\n",
    "            'D': [0.33, 0, 0.33, 0.33],\n",
    "            'B': [0, 0.33, 0.33, 0.33],\n",
    "            'N': [0.25, 0.25, 0.25, 0.25],\n",
    "        }\n",
    "\n",
    "    encoded_sequence = []\n",
    "    for i, base in enumerate(sequence):\n",
    "        base_encoding =  mapping.get(base)\n",
    "        if(quality_scores[i]):\n",
    "            quality = quality_scores[i]\n",
    "\n",
    "        else:\n",
    "                quality=0\n",
    "        normalized_quality = 1.0 if quality >= 50 else (quality - 30) / 20 if quality > 30 else 0.0\n",
    "\n",
    "        encoded_sequence.append(base_encoding + [normalized_quality])\n",
    "        \n",
    "    return np.array(encoded_sequence)\n",
    "\n",
    "def encode_fastq(sequences,quality,max_sequence_length=253):\n",
    "    encoded_sequences = []\n",
    "    for qual,seq in zip(quality,sequences):\n",
    "        if len(seq) < max_sequence_length:\n",
    "            seq += 'N' * (max_sequence_length - len(seq))\n",
    "            qual.extend([0] * len(seq))# Pad sequence with 'N' to reach max length\n",
    "        encoded_seq = encode_sequence_with_quality(seq[:max_sequence_length],qual)  # Truncate or pad to fixed length\n",
    "        encoded_sequences.append(encoded_seq)\n",
    "    return np.array(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def promediar_cal(calidades):\n",
    "    calidad=[]\n",
    "    for cal in calidades:\n",
    "        cal=np.array(cal)\n",
    "        suma=np.sum(cal)\n",
    "        calidad.append(round(suma/len(cal), 2))\n",
    "    return calidad\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_calidades2(calidades):\n",
    "    qual1=0\n",
    "    qual2=0\n",
    "    for cal in calidades:\n",
    "        \n",
    "        if cal < 30:\n",
    "            qual1=qual1+1\n",
    "        else:\n",
    "            qual2=qual2+1# Si el número es mayor que 50, devolver 1\n",
    "    return qual1,qual2\n",
    "\n",
    "def contar_cal(calidades):\n",
    "    cal1=[]\n",
    "    cal2=[]\n",
    "    for cal in calidades:\n",
    "        \n",
    "        sum1,sum2=procesar_calidades2(cal)\n",
    "        \n",
    "        cal1.append(sum1)\n",
    "        cal2.append(sum2)\n",
    "    return cal1,cal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargando archivos, it:1\n",
      "(19231, 24)\n",
      "cargando archivos, it:2\n",
      "(19231, 24)\n",
      "cargando archivos, it:3\n",
      "(7921, 24)\n",
      "cargando archivos, it:4\n",
      "(12222, 24)\n",
      "cargando archivos, it:5\n",
      "(13578, 24)\n",
      "cargando archivos, it:6\n",
      "(17790, 24)\n",
      "cargando archivos, it:7\n",
      "(7800, 24)\n",
      "cargando archivos, it:8\n",
      "(21082, 24)\n",
      "cargando archivos, it:9\n",
      "(7753, 24)\n",
      "cargando archivos, it:10\n",
      "(10325, 24)\n",
      "cargando archivos, it:11\n",
      "(4586, 24)\n",
      "cargando archivos, it:12\n",
      "(6152, 24)\n",
      "cargando archivos, it:13\n",
      "(12794, 24)\n",
      "cargando archivos, it:14\n",
      "(24237, 24)\n",
      "cargando archivos, it:15\n",
      "(9323, 24)\n",
      "cargando archivos, it:16\n",
      "(2927, 24)\n",
      "cargando archivos, it:17\n",
      "(9299, 24)\n",
      "cargando archivos, it:18\n",
      "(5892, 24)\n",
      "cargando archivos, it:19\n",
      "(7727, 24)\n",
      "cargando archivos, it:20\n",
      "(3714, 24)\n",
      "cargando archivos, it:21\n",
      "(3421, 24)\n",
      "cargando archivos, it:22\n",
      "(9081, 24)\n",
      "cargando archivos, it:23\n",
      "(13912, 24)\n",
      "cargando archivos, it:24\n",
      "(11063, 24)\n",
      "cargando archivos, it:25\n",
      "(5196, 24)\n",
      "cargando archivos, it:26\n",
      "(14629, 24)\n",
      "cargando archivos, it:27\n",
      "(3838, 24)\n",
      "cargando archivos, it:28\n",
      "(24733, 24)\n",
      "cargando archivos, it:29\n",
      "(4493, 24)\n",
      "cargando archivos, it:30\n",
      "(2454, 24)\n",
      "cargando archivos, it:31\n",
      "(14, 24)\n",
      "cargando archivos, it:32\n",
      "(3832, 24)\n",
      "cargando archivos, it:33\n",
      "(5958, 24)\n",
      "cargando archivos, it:34\n",
      "(5384, 24)\n",
      "cargando archivos, it:35\n",
      "(8074, 24)\n",
      "cargando archivos, it:36\n",
      "(17061, 24)\n",
      "cargando archivos, it:37\n",
      "(1739, 24)\n",
      "cargando archivos, it:38\n",
      "(12467, 24)\n",
      "cargando archivos, it:39\n",
      "(7962, 24)\n",
      "cargando archivos, it:40\n",
      "(15400, 24)\n",
      "cargando archivos, it:41\n",
      "(4448, 24)\n",
      "cargando archivos, it:42\n",
      "(38760, 24)\n",
      "cargando archivos, it:43\n",
      "(14515, 24)\n",
      "cargando archivos, it:44\n",
      "(13148, 24)\n",
      "cargando archivos, it:45\n",
      "(8524, 24)\n",
      "cargando archivos, it:46\n",
      "(11860, 24)\n",
      "cargando archivos, it:47\n",
      "(30678, 24)\n",
      "cargando archivos, it:48\n",
      "(15270, 24)\n",
      "cargando archivos, it:49\n",
      "(9276, 24)\n",
      "cargando archivos, it:50\n",
      "(5079, 24)\n",
      "cargando archivos, it:51\n",
      "(23411, 24)\n",
      "cargando archivos, it:52\n",
      "(14846, 24)\n",
      "cargando archivos, it:53\n",
      "(5651, 24)\n",
      "cargando archivos, it:54\n",
      "(30012, 24)\n",
      "cargando archivos, it:55\n",
      "(12891, 24)\n",
      "cargando archivos, it:56\n",
      "(13055, 24)\n",
      "cargando archivos, it:57\n",
      "(8274, 24)\n",
      "cargando archivos, it:58\n",
      "(8293, 24)\n",
      "cargando archivos, it:59\n",
      "(37695, 24)\n",
      "cargando archivos, it:60\n",
      "(4368, 24)\n",
      "cargando archivos, it:61\n",
      "(6763, 24)\n",
      "cargando archivos, it:62\n",
      "(22292, 24)\n",
      "cargando archivos, it:63\n",
      "(14939, 24)\n",
      "cargando archivos, it:64\n",
      "(8343, 24)\n",
      "cargando archivos, it:65\n",
      "(4749, 24)\n",
      "cargando archivos, it:66\n",
      "(28789, 24)\n",
      "cargando archivos, it:67\n",
      "(14537, 24)\n",
      "cargando archivos, it:68\n",
      "(11198, 24)\n",
      "cargando archivos, it:69\n",
      "(320, 24)\n",
      "cargando archivos, it:70\n",
      "(14580, 24)\n",
      "cargando archivos, it:71\n",
      "(3183, 24)\n",
      "cargando archivos, it:72\n",
      "(10340, 24)\n",
      "cargando archivos, it:73\n",
      "(14026, 24)\n",
      "cargando archivos, it:74\n",
      "(5294, 24)\n",
      "cargando archivos, it:75\n",
      "(7243, 24)\n",
      "cargando archivos, it:76\n",
      "(6640, 24)\n",
      "cargando archivos, it:77\n",
      "(8826, 24)\n",
      "cargando archivos, it:78\n",
      "(5106, 24)\n",
      "cargando archivos, it:79\n",
      "(15412, 24)\n",
      "cargando archivos, it:80\n",
      "(5673, 24)\n",
      "cargando archivos, it:81\n",
      "(32886, 24)\n",
      "cargando archivos, it:82\n",
      "(13774, 24)\n",
      "cargando archivos, it:83\n",
      "(28752, 24)\n",
      "cargando archivos, it:84\n",
      "(4625, 24)\n",
      "cargando archivos, it:85\n",
      "(5616, 24)\n",
      "cargando archivos, it:86\n",
      "(875, 24)\n",
      "cargando archivos, it:87\n",
      "(2236, 24)\n",
      "cargando archivos, it:88\n",
      "(7793, 24)\n",
      "cargando archivos, it:89\n",
      "(14221, 24)\n",
      "cargando archivos, it:90\n",
      "(7675, 24)\n",
      "cargando archivos, it:91\n",
      "(6715, 24)\n",
      "cargando archivos, it:92\n",
      "(8210, 24)\n",
      "cargando archivos, it:93\n",
      "(9786, 24)\n",
      "cargando archivos, it:94\n",
      "(18119, 24)\n",
      "cargando archivos, it:95\n",
      "(5068, 24)\n",
      "cargando archivos, it:96\n",
      "(8094, 24)\n",
      "cargando archivos, it:97\n",
      "(9087, 24)\n",
      "cargando archivos, it:98\n",
      "(6283, 24)\n",
      "cargando archivos, it:99\n",
      "(6096, 24)\n",
      "cargando archivos, it:100\n",
      "(8933, 24)\n",
      "cargando archivos, it:101\n",
      "(6305, 24)\n",
      "cargando archivos, it:102\n",
      "(7546, 24)\n",
      "cargando archivos, it:103\n",
      "(4433, 24)\n",
      "cargando archivos, it:104\n",
      "(10470, 24)\n",
      "cargando archivos, it:105\n",
      "(5489, 24)\n",
      "cargando archivos, it:106\n",
      "(7061, 24)\n",
      "cargando archivos, it:107\n",
      "(5379, 24)\n",
      "cargando archivos, it:108\n",
      "(5700, 24)\n",
      "cargando archivos, it:109\n",
      "(23942, 24)\n",
      "cargando archivos, it:110\n",
      "(40113, 24)\n",
      "cargando archivos, it:111\n",
      "(5078, 24)\n",
      "cargando archivos, it:112\n",
      "(7145, 24)\n",
      "cargando archivos, it:113\n",
      "(3717, 24)\n",
      "cargando archivos, it:114\n",
      "(3499, 24)\n",
      "cargando archivos, it:115\n",
      "(23523, 24)\n",
      "cargando archivos, it:116\n",
      "(21060, 24)\n",
      "cargando archivos, it:117\n",
      "(18559, 24)\n",
      "cargando archivos, it:118\n",
      "(5869, 24)\n",
      "cargando archivos, it:119\n",
      "(17070, 24)\n",
      "cargando archivos, it:120\n",
      "(7499, 24)\n",
      "cargando archivos, it:121\n",
      "(9297, 24)\n",
      "cargando archivos, it:122\n",
      "(6286, 24)\n",
      "cargando archivos, it:123\n",
      "(6695, 24)\n",
      "cargando archivos, it:124\n",
      "(18736, 24)\n",
      "cargando archivos, it:125\n",
      "(5783, 24)\n",
      "cargando archivos, it:126\n",
      "(27508, 24)\n",
      "cargando archivos, it:127\n",
      "(4183, 24)\n",
      "cargando archivos, it:128\n",
      "(7989, 24)\n",
      "cargando archivos, it:129\n",
      "(9132, 24)\n",
      "cargando archivos, it:130\n",
      "(6775, 24)\n",
      "cargando archivos, it:131\n",
      "(6893, 24)\n",
      "cargando archivos, it:132\n",
      "(3756, 24)\n",
      "cargando archivos, it:133\n",
      "(4137, 24)\n",
      "cargando archivos, it:134\n",
      "(4806, 24)\n",
      "cargando archivos, it:135\n",
      "(4238, 24)\n",
      "cargando archivos, it:136\n",
      "(3320, 24)\n",
      "cargando archivos, it:137\n",
      "(7356, 24)\n",
      "cargando archivos, it:138\n",
      "(9964, 24)\n",
      "cargando archivos, it:139\n",
      "(9207, 24)\n",
      "cargando archivos, it:140\n",
      "(83, 24)\n",
      "cargando archivos, it:141\n",
      "(7377, 24)\n",
      "cargando archivos, it:142\n",
      "(6854, 24)\n",
      "cargando archivos, it:143\n",
      "(6758, 24)\n",
      "cargando archivos, it:144\n",
      "(9538, 24)\n",
      "cargando archivos, it:145\n",
      "(5533, 24)\n",
      "cargando archivos, it:146\n",
      "(19277, 24)\n",
      "cargando archivos, it:147\n",
      "(3736, 24)\n",
      "cargando archivos, it:148\n",
      "(7070, 24)\n",
      "cargando archivos, it:149\n",
      "(5129, 24)\n",
      "cargando archivos, it:150\n",
      "(4549, 24)\n",
      "cargando archivos, it:151\n",
      "(10963, 24)\n",
      "cargando archivos, it:152\n",
      "(5542, 24)\n",
      "cargando archivos, it:153\n",
      "(6491, 24)\n",
      "cargando archivos, it:154\n",
      "(11587, 24)\n",
      "cargando archivos, it:155\n",
      "(2558, 24)\n",
      "cargando archivos, it:156\n",
      "(485, 24)\n",
      "cargando archivos, it:157\n",
      "(13082, 24)\n",
      "cargando archivos, it:158\n",
      "(10682, 24)\n",
      "cargando archivos, it:159\n",
      "(4931, 24)\n",
      "cargando archivos, it:160\n",
      "(6460, 24)\n",
      "cargando archivos, it:161\n",
      "(13926, 24)\n",
      "cargando archivos, it:162\n",
      "(5954, 24)\n",
      "cargando archivos, it:163\n",
      "(7608, 24)\n",
      "cargando archivos, it:164\n",
      "(14819, 24)\n",
      "cargando archivos, it:165\n",
      "(5846, 24)\n",
      "cargando archivos, it:166\n",
      "(4929, 24)\n",
      "cargando archivos, it:167\n",
      "(17778, 24)\n",
      "cargando archivos, it:168\n",
      "(2415, 24)\n",
      "cargando archivos, it:169\n",
      "(5757, 24)\n",
      "cargando archivos, it:170\n",
      "(4917, 24)\n",
      "cargando archivos, it:171\n",
      "(5710, 24)\n",
      "cargando archivos, it:172\n",
      "(7977, 24)\n",
      "cargando archivos, it:173\n",
      "(16074, 24)\n",
      "cargando archivos, it:174\n",
      "(12535, 24)\n",
      "cargando archivos, it:175\n",
      "(2969, 24)\n",
      "cargando archivos, it:176\n",
      "(19620, 24)\n",
      "cargando archivos, it:177\n",
      "(10217, 24)\n",
      "cargando archivos, it:178\n",
      "(12898, 24)\n",
      "cargando archivos, it:179\n",
      "(11083, 24)\n",
      "cargando archivos, it:180\n",
      "(11831, 24)\n",
      "cargando archivos, it:181\n",
      "(21405, 24)\n",
      "cargando archivos, it:182\n",
      "(4932, 24)\n",
      "cargando archivos, it:183\n",
      "(4706, 24)\n",
      "cargando archivos, it:184\n",
      "(5664, 24)\n",
      "cargando archivos, it:185\n",
      "(6067, 24)\n",
      "cargando archivos, it:186\n",
      "(6573, 24)\n",
      "cargando archivos, it:187\n",
      "(5129, 24)\n",
      "cargando archivos, it:188\n",
      "(70, 24)\n",
      "cargando archivos, it:189\n",
      "(21931, 24)\n",
      "cargando archivos, it:190\n",
      "(12074, 24)\n",
      "cargando archivos, it:191\n",
      "(4750, 24)\n",
      "cargando archivos, it:192\n",
      "(18839, 24)\n",
      "cargando archivos, it:193\n",
      "(4827, 24)\n",
      "cargando archivos, it:194\n",
      "(14164, 24)\n",
      "cargando archivos, it:195\n",
      "(18317, 24)\n",
      "cargando archivos, it:196\n",
      "(9761, 24)\n",
      "cargando archivos, it:197\n",
      "(9846, 24)\n",
      "cargando archivos, it:198\n",
      "(5509, 24)\n",
      "cargando archivos, it:199\n",
      "(2560, 24)\n",
      "cargando archivos, it:200\n",
      "(7810, 24)\n",
      "cargando archivos, it:201\n",
      "(17268, 24)\n",
      "cargando archivos, it:202\n",
      "(4294, 24)\n",
      "cargando archivos, it:203\n",
      "(7107, 24)\n",
      "cargando archivos, it:204\n",
      "(4522, 24)\n",
      "cargando archivos, it:205\n",
      "(16579, 24)\n",
      "cargando archivos, it:206\n",
      "(6320, 24)\n",
      "cargando archivos, it:207\n",
      "(12674, 24)\n",
      "cargando archivos, it:208\n",
      "(9335, 24)\n",
      "cargando archivos, it:209\n",
      "(8335, 24)\n",
      "cargando archivos, it:210\n",
      "(4098, 24)\n",
      "cargando archivos, it:211\n",
      "(14251, 24)\n",
      "cargando archivos, it:212\n",
      "(19160, 24)\n",
      "cargando archivos, it:213\n",
      "(14462, 24)\n",
      "cargando archivos, it:214\n",
      "(2315, 24)\n",
      "cargando archivos, it:215\n",
      "(11198, 24)\n",
      "cargando archivos, it:216\n",
      "(5517, 24)\n",
      "cargando archivos, it:217\n",
      "(4938, 24)\n",
      "cargando archivos, it:218\n",
      "(9799, 24)\n",
      "cargando archivos, it:219\n",
      "(12405, 24)\n",
      "cargando archivos, it:220\n",
      "(15304, 24)\n",
      "cargando archivos, it:221\n",
      "(7526, 24)\n",
      "cargando archivos, it:222\n",
      "(11993, 24)\n",
      "cargando archivos, it:223\n",
      "(5409, 24)\n",
      "cargando archivos, it:224\n",
      "(1495, 24)\n",
      "cargando archivos, it:225\n",
      "(14838, 24)\n",
      "cargando archivos, it:226\n",
      "(8341, 24)\n",
      "cargando archivos, it:227\n",
      "(14720, 24)\n",
      "cargando archivos, it:228\n",
      "(8798, 24)\n",
      "cargando archivos, it:229\n",
      "(14410, 24)\n",
      "cargando archivos, it:230\n",
      "(5722, 24)\n",
      "cargando archivos, it:231\n",
      "(5160, 24)\n",
      "cargando archivos, it:232\n",
      "(9494, 24)\n",
      "cargando archivos, it:233\n",
      "(6424, 24)\n",
      "cargando archivos, it:234\n",
      "(8046, 24)\n",
      "cargando archivos, it:235\n",
      "(23712, 24)\n",
      "cargando archivos, it:236\n",
      "(7088, 24)\n",
      "cargando archivos, it:237\n",
      "(21245, 24)\n",
      "cargando archivos, it:238\n",
      "(14013, 24)\n",
      "cargando archivos, it:239\n",
      "(19830, 24)\n",
      "cargando archivos, it:240\n",
      "(2714, 24)\n",
      "cargando archivos, it:241\n",
      "(18920, 24)\n",
      "cargando archivos, it:242\n",
      "(28068, 24)\n",
      "cargando archivos, it:243\n",
      "(4082, 24)\n",
      "cargando archivos, it:244\n",
      "(13624, 24)\n",
      "cargando archivos, it:245\n",
      "(11441, 24)\n",
      "cargando archivos, it:246\n",
      "(7038, 24)\n",
      "cargando archivos, it:247\n",
      "(8810, 24)\n",
      "cargando archivos, it:248\n",
      "(9303, 24)\n",
      "cargando archivos, it:249\n",
      "(7200, 24)\n",
      "cargando archivos, it:250\n",
      "(9729, 24)\n",
      "cargando archivos, it:251\n",
      "(9375, 24)\n",
      "cargando archivos, it:252\n",
      "(5579, 24)\n",
      "cargando archivos, it:253\n",
      "(18197, 24)\n",
      "cargando archivos, it:254\n",
      "(2851, 24)\n",
      "cargando archivos, it:255\n",
      "(31614, 24)\n",
      "cargando archivos, it:256\n",
      "(6048, 24)\n",
      "cargando archivos, it:257\n",
      "(18883, 24)\n",
      "cargando archivos, it:258\n",
      "(9286, 24)\n",
      "cargando archivos, it:259\n",
      "(11529, 24)\n",
      "cargando archivos, it:260\n",
      "(15667, 24)\n",
      "cargando archivos, it:261\n",
      "(6652, 24)\n",
      "cargando archivos, it:262\n",
      "(6868, 24)\n",
      "cargando archivos, it:263\n",
      "(3178, 24)\n",
      "cargando archivos, it:264\n",
      "(10585, 24)\n",
      "cargando archivos, it:265\n",
      "(19906, 24)\n",
      "cargando archivos, it:266\n",
      "(4920, 24)\n",
      "cargando archivos, it:267\n",
      "(161, 24)\n",
      "cargando archivos, it:268\n",
      "(6670, 24)\n",
      "cargando archivos, it:269\n",
      "(16679, 24)\n",
      "cargando archivos, it:270\n",
      "(6949, 24)\n",
      "cargando archivos, it:271\n",
      "(4616, 24)\n",
      "cargando archivos, it:272\n",
      "(11612, 24)\n",
      "cargando archivos, it:273\n",
      "(13696, 24)\n",
      "cargando archivos, it:274\n",
      "(9010, 24)\n",
      "cargando archivos, it:275\n",
      "(6680, 24)\n",
      "cargando archivos, it:276\n",
      "(17277, 24)\n",
      "cargando archivos, it:277\n",
      "(18540, 24)\n",
      "cargando archivos, it:278\n",
      "(15213, 24)\n",
      "cargando archivos, it:279\n",
      "(5152, 24)\n",
      "cargando archivos, it:280\n",
      "(4780, 24)\n",
      "cargando archivos, it:281\n",
      "(9600, 24)\n",
      "cargando archivos, it:282\n",
      "(3969, 24)\n",
      "cargando archivos, it:283\n",
      "(6297, 24)\n",
      "cargando archivos, it:284\n",
      "(7820, 24)\n",
      "cargando archivos, it:285\n",
      "(6136, 24)\n",
      "cargando archivos, it:286\n",
      "(12535, 24)\n",
      "cargando archivos, it:287\n",
      "(17285, 24)\n",
      "cargando archivos, it:288\n",
      "(7732, 24)\n",
      "cargando archivos, it:289\n",
      "(4136, 24)\n",
      "cargando archivos, it:290\n",
      "(5021, 24)\n",
      "cargando archivos, it:291\n",
      "(4557, 24)\n",
      "cargando archivos, it:292\n",
      "(19128, 24)\n",
      "cargando archivos, it:293\n",
      "(10943, 24)\n",
      "cargando archivos, it:294\n",
      "(1012, 24)\n",
      "cargando archivos, it:295\n",
      "(34712, 24)\n",
      "cargando archivos, it:296\n",
      "(12370, 24)\n",
      "cargando archivos, it:297\n",
      "(5213, 24)\n",
      "cargando archivos, it:298\n",
      "(9604, 24)\n",
      "cargando archivos, it:299\n",
      "(14141, 24)\n",
      "cargando archivos, it:300\n",
      "(14764, 24)\n",
      "cargando archivos, it:301\n",
      "(6478, 24)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "a=[]\n",
    "b=[]\n",
    "for i in range(0, len(paths), batch_size):\n",
    "    batch_paths = paths[i:i+batch_size]  # Get a batch of paths\n",
    "    # Process each folder in the batch\n",
    "    for j, path in enumerate(batch_paths):\n",
    "        #combined=[]\n",
    "        print(f\"cargando archivos, it:{i+j+1}\")\n",
    "        paired_files = buscar_archivos_fastq(path)\n",
    "        \n",
    "        fasta_files= buscar_archivos_fasta(path)\n",
    "        \n",
    "        items_seqs= process_paired_fastq_files(paired_files[0], paired_files[1])\n",
    "\n",
    "        #retorno\n",
    "        #np.array(sequences_r1),    0\n",
    "        # np.array(sequences_r2),   1\n",
    "        #qualities_f,               2\n",
    "        # qualities_r,              3\n",
    "        # ids                       4\n",
    "        # atributos fr              5\n",
    "        # atributos rv              6\n",
    "        cal_bu1,cal_ma1=contar_cal(items_seqs[2])\n",
    "        cal_bu2,cal_ma2=contar_cal(items_seqs[3])\n",
    "        #prom_cal1=promediar_cal(items_seqs[2])\n",
    "        #prom_cal2=promediar_cal(items_seqs[3])\n",
    "        \"\"\"\n",
    "        for item in items_seqs[2]:\n",
    "            print(f\"np prom_ {np.mean(np.array(item))}\")\n",
    "            print(f\"np median_ {np.median(np.array(item))}\")\n",
    "            print(f\"np desviacion_ {np.std(np.array(item))}\")\n",
    "            print(f\"varianza {np.var(np.array(item))}\")\n",
    "            \"\"\"\n",
    "        atributos_fr=items_seqs[5]\n",
    "        atributos_rv=items_seqs[6]\n",
    "        \n",
    "        \n",
    "        for k in range(0,len(atributos_fr)):\n",
    "            atributos_fr[k].append(cal_bu1[k])\n",
    "            atributos_fr[k].append(cal_ma1[k])\n",
    "            atributos_fr[k].append(np.mean(np.array(items_seqs[2][k])))\n",
    "            atributos_fr[k].append(np.median(np.array(items_seqs[2][k])))\n",
    "            atributos_fr[k].append(np.std(np.array(items_seqs[2][k])))\n",
    "            atributos_fr[k].append(np.var(np.array(items_seqs[2][k])))\n",
    "            \n",
    "        for k in range(0,len(atributos_rv)):\n",
    "            atributos_rv[k].append(cal_bu2[k])\n",
    "            atributos_rv[k].append(cal_ma2[k])\n",
    "            atributos_rv[k].append(np.mean(np.array(items_seqs[3][k])))\n",
    "            atributos_rv[k].append(np.median(np.array(items_seqs[3][k])))\n",
    "            atributos_rv[k].append(np.std(np.array(items_seqs[3][k])))\n",
    "            atributos_rv[k].append(np.var(np.array(items_seqs[3][k])))\n",
    "        #d=np.concatenate((atributos_fr,cal1),axis=0)\n",
    "        #print(d[0])\n",
    "\n",
    "        items_tgt=ver_si_contig_existe(fasta_files[0],items_seqs[4])\n",
    "        \n",
    "        y_train = np.ravel(items_tgt)\n",
    "        \n",
    "        x_train=np.concatenate((atributos_fr,atributos_rv),axis=1)\n",
    "        \n",
    "        #a.append(np.concatenate((atributos_fr,atributos_rv),axis=0))\n",
    "        print(x_train.shape)\n",
    "\n",
    "        # Aplanar X_seq2\n",
    "        #a.append(X_combined_flat)\n",
    "        #b.append(y_train)\n",
    "\n",
    "        np.save(f'caracteristicas4/atributos_{i+j+1}.npy', np.array(x_train))\n",
    "        np.save(f'caracteristicas4/resultados_{i+j+1}.npy', np.array(y_train))\n",
    "\n",
    "        #if(i+j+1)==1:\n",
    "#a = np.concatenate(a, axis=0)\n",
    "\n",
    "#b = np.concatenate(b, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "possible_letters = ['A', 'C', 'G', 'T', 'M', 'R', 'W', 'S', 'Y', 'K', 'V', 'H', 'D', 'B', 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6478, 18)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "#print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(54735, 2530)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(42312, 2530)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,input_1,input_2, targets, batch_size=32,epochs=2):\n",
    "\n",
    "    return model.fit(\n",
    "        x=[input_1, input_2],\n",
    "        y=targets,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'adapted_binary_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/soto/Desktop/project/pruebascontig2.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig2.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m adapted_binary_model()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'adapted_binary_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = adapted_binary_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-23 23:06:36.561532: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_7/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 3s 11ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - 1s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      " 64/138 [============>.................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/soto/Desktop/project/pruebascontig1.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         encoded_fr,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         encoded_rv,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         items_tgt,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m#initial_epoch=initial_epoch\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     )\n",
      "\u001b[1;32m/home/soto/Desktop/project/pruebascontig1.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model,input_1,input_2, targets, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,epochs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         x\u001b[39m=\u001b[39;49m[input_1, input_2],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         y\u001b[39m=\u001b[39;49mtargets,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_model(\n",
    "        model,\n",
    "        encoded_fr,\n",
    "        encoded_rv,\n",
    "        items_tgt,\n",
    "        \n",
    "        epochs=100\n",
    "        #initial_epoch=initial_epoch\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq1_flat = np.reshape(encoded_fr, (encoded_fr.shape[0], -1))  # Aplanar X_seq1\n",
    "X_seq2_flat = np.reshape(encoded_rv, (encoded_rv.shape[0], -1))  # Aplanar X_seq2\n",
    "\n",
    "# Concatenar los datos aplanados\n",
    "X_combined_flat = np.concatenate((X_seq1_flat, X_seq2_flat), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5517,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.ravel(items_tgt)  # Aplanar X_seq2\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/soto/Desktop/project/pruebascontig1 copy.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m svm \u001b[39m=\u001b[39m SVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Entrenar el modelo SVM\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m svm\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Predecir en el conjunto de prueba\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_pred \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    251\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/sklearn/svm/_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    315\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    317\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    319\u001b[0m (\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[1;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[1;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[0;32m--> 329\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    330\u001b[0m     X,\n\u001b[1;32m    331\u001b[0m     y,\n\u001b[1;32m    332\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[1;32m    333\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    334\u001b[0m     \u001b[39m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    335\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m_class_weight\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[1;32m    336\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    337\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m    338\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[1;32m    339\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[1;32m    340\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[1;32m    341\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[1;32m    342\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    343\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[1;32m    344\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[1;32m    345\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    346\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    347\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    348\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[1;32m    349\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el clasificador SVM\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Entrenar el modelo SVM\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Calcular la exactitud\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10947, 14764]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/soto/Desktop/project/pruebascontig1 copy.ipynb Cell 25\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report, confusion_matrix, precision_score, recall_score, f1_score\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Calcular la matriz de confusión\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m conf_matrix \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/soto/Desktop/project/pruebascontig1%20copy.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(conf_matrix)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    327\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-test/lib/python3.10/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10947, 14764]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calcular precision, recall y f1-score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')\n",
    "\n",
    "# Reporte de clasificación\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear el heatmap de la matriz de confusión\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "#X_train1, X_test1, X_train2, X_test2, y_train, y_test = train_test_split(X_input1_flat, X_input2_flat, y_output_flat, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(a, b, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el regresor RandomForest\n",
    "rf_regressor = RandomForestRegressor(n_estimators=30, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "#rf_regressor.fit([X_train1, X_train2], y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "#predictions = rf_regressor.predict([X_test1, X_test2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.21148377739688326\n",
      "R-squared: 0.02409219605763624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.21148377739688326\n",
    "R-squared: 0.02409219605763624"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.21793884920426165\n",
    "R-squared: -0.01440627993256327\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.22119389956950966\n",
    "R-squared: -0.029557059814445008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.21692751518356335\n",
    "R-squared: -0.009698979763494986"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cambio de paradigma, dando conteo de letras y largo puro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.17795166483968214\n",
    "R-squared: 0.1788286525842"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.18141360431683015\n",
    "R-squared: 0.1591024070537358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.18141360431683015\n",
    "R-squared: 0.1591024070537358\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.1755127574225682\n",
    "R-squared: 0.17107820826153897\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error: 0.17888907529190715\n",
    "R-squared: 0.15513233914734803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1104,)\n",
      "0.1625\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargando archivos, it: 1\n",
      "(5517, 253, 5, 1)\n",
      "(5517, 253, 5, 1)\n",
      "(5517, 1)\n",
      "(5517,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 2\n",
      "(12898, 253, 5, 1)\n",
      "(12898, 253, 5, 1)\n",
      "(12898, 1)\n",
      "(12898,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 3\n",
      "(18839, 253, 5, 1)\n",
      "(18839, 253, 5, 1)\n",
      "(18839, 1)\n",
      "(18839,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 4\n",
      "(71, 253, 5, 1)\n",
      "(71, 253, 5, 1)\n",
      "(71, 1)\n",
      "(71,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 5\n",
      "(4987, 253, 5, 1)\n",
      "(4987, 253, 5, 1)\n",
      "(4987, 1)\n",
      "(4987,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 6\n",
      "(5335, 253, 5, 1)\n",
      "(5335, 253, 5, 1)\n",
      "(5335, 1)\n",
      "(5335,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 7\n",
      "(7088, 253, 5, 1)\n",
      "(7088, 253, 5, 1)\n",
      "(7088, 1)\n",
      "(7088,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 8\n",
      "(11587, 253, 5, 1)\n",
      "(11587, 253, 5, 1)\n",
      "(11587, 1)\n",
      "(11587,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 9\n",
      "(5700, 253, 5, 1)\n",
      "(5700, 253, 5, 1)\n",
      "(5700, 1)\n",
      "(5700,)\n",
      "Mean Squared Error: 0.0\n",
      "R-squared: 1.0\n",
      "cargando archivos, it: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "batch_size = 5\n",
    "  \n",
    "for i in range(0, len(paths), batch_size):\n",
    "    batch_paths = paths[i:i+batch_size]  # Get a batch of paths\n",
    "    # Process each folder in the batch\n",
    "    for j, path in enumerate(batch_paths):\n",
    "        #combined=[]\n",
    "        print(\"cargando archivos, it:\",i+j+1)\n",
    "        paired_files = buscar_archivos_fastq(path)\n",
    "        fasta_files= buscar_archivos_fasta(path)\n",
    "        \n",
    "        items_seqs= process_paired_fastq_files(paired_files[0], paired_files[1])\n",
    "        #retorno\n",
    "        #np.array(sequences_r1),    0\n",
    "        # np.array(sequences_r2),   1\n",
    "        #qualities_f,               2\n",
    "        # qualities_r,              3\n",
    "        # ids                       4\n",
    "\n",
    "        items_tgt=ver_si_contig_existe(fasta_files[0],fasta_files[1],items_seqs[4])\n",
    "        \n",
    "        encoded_fr=encode_fastq(items_seqs[0],items_seqs[2])\n",
    "        encoded_rv=encode_fastq(items_seqs[1],items_seqs[3])\n",
    "        \n",
    "        encoded_fr = encoded_fr.reshape(-1, 253, 5, 1)\n",
    "        encoded_rv= encoded_rv.reshape(-1, 253, 5, 1)\n",
    "        items_tgt=np.array(items_tgt)\n",
    "        items_tgt = items_tgt.reshape(-1, 1)\n",
    "    \n",
    "        #a=np.stack([encoded_fr,encoded_rv],axis=1)\n",
    "        #print(encoded_tg.shape)\n",
    "        #print(a.shape)\n",
    "        print(encoded_fr.shape)\n",
    "        print(encoded_rv.shape)\n",
    "        print(items_tgt.shape)\n",
    "        #print(cal_1.shape)\n",
    "        #print(cal_1.shape)\n",
    "        \n",
    "        X_seq1_flat = np.reshape(encoded_fr, (encoded_fr.shape[0], -1))  # Aplanar X_seq1\n",
    "        X_seq2_flat = np.reshape(encoded_rv, (encoded_rv.shape[0], -1))  # Aplanar X_seq2\n",
    "\n",
    "        # Concatenar los datos aplanados\n",
    "        X_combined_flat = np.concatenate((X_seq1_flat, X_seq2_flat), axis=1)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(items_tgt)  # Aplanar X_seq2\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined_flat, y_train , test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el regresor RandomForest\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "#rf_regressor.fit([X_train1, X_train2], y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "#predictions = rf_regressor.predict([X_test1, X_test2])\n",
    "\n",
    "# Calcular el error (si es necesario)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in rf_regressor.estimators_:  # Puedes cambiar el índice para visualizar otro árbol\n",
    "\n",
    "# Grafica el árbol\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(tree, filled=True, feature_names=[f'feature_{i}' for i in range(X_combined_flat.shape[1])], class_names=['0', '1'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_fr = np.load(f\"seqs/encoded_fr_50.npy\")\n",
    "encoded_rv = np.load(f\"seqs/encoded_rv_50.npy\")\n",
    "encoded_tg = np.load(f\"seqs/encoded_tg_50.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4987, 253, 5, 1)\n",
      "(4987, 253, 5, 1)\n",
      "(4987, 1)\n",
      "(4987,)\n"
     ]
    }
   ],
   "source": [
    "items_seqs= process_paired_fastq_files(paired_files[0], paired_files[1])\n",
    "#retorno\n",
    "#np.array(sequences_r1),    0\n",
    "# np.array(sequences_r2),   1\n",
    "#qualities_f,               2\n",
    "# qualities_r,              3\n",
    "# ids                       4\n",
    "\n",
    "items_tgt=ver_si_contig_existe(fasta_files[0],fasta_files[1],items_seqs[4])\n",
    "\n",
    "encoded_fr=encode_fastq(items_seqs[0],items_seqs[2])\n",
    "encoded_rv=encode_fastq(items_seqs[1],items_seqs[3])\n",
    "\n",
    "encoded_fr = encoded_fr.reshape(-1, 253, 5, 1)\n",
    "encoded_rv= encoded_rv.reshape(-1, 253, 5, 1)\n",
    "items_tgt=np.array(items_tgt)\n",
    "items_tgt = items_tgt.reshape(-1, 1)\n",
    "\n",
    "#a=np.stack([encoded_fr,encoded_rv],axis=1)\n",
    "#print(encoded_tg.shape)\n",
    "#print(a.shape)\n",
    "print(encoded_fr.shape)\n",
    "print(encoded_rv.shape)\n",
    "print(items_tgt.shape)\n",
    "#print(cal_1.shape)\n",
    "#print(cal_1.shape)\n",
    "\n",
    "X_seq1_flat = np.reshape(encoded_fr, (encoded_fr.shape[0], -1))  # Aplanar X_seq1\n",
    "X_seq2_flat = np.reshape(encoded_rv, (encoded_rv.shape[0], -1))  # Aplanar X_seq2\n",
    "\n",
    "# Concatenar los datos aplanados\n",
    "X_combined_flat = np.concatenate((X_seq1_flat, X_seq2_flat), axis=1)\n",
    "\n",
    "y_train = np.ravel(items_tgt)  # Aplanar X_seq2\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cargando archivos, it:1\n"
     ]
    }
   ],
   "source": [
    "print(f\"cargando archivos, it:{i+j+1}\")\n",
    "paired_files = buscar_archivos_fastq(\"../tutorialM/datos/sets/Folder_50\")\n",
    "\n",
    "fasta_files= buscar_archivos_fasta(\"../tutorialM/datos/sets/Folder_50\")\n",
    "\n",
    "items_seqs= process_paired_fastq_files(paired_files[0], paired_files[1])\n",
    "\n",
    "#retorno\n",
    "#np.array(sequences_r1),    0\n",
    "# np.array(sequences_r2),   1\n",
    "#qualities_f,               2\n",
    "# qualities_r,              3\n",
    "# ids                       4\n",
    "# atributos fr              5\n",
    "# atributos rv              6\n",
    "\n",
    "atributos_fr=items_seqs[5]\n",
    "atributos_rv=items_seqs[6]\n",
    "\n",
    "\n",
    "        \n",
    "items_tgt=ver_si_contig_existe(fasta_files[0],fasta_files[1],items_seqs[4])\n",
    "\n",
    "y_prueba = np.ravel(items_tgt)\n",
    "x_prueba=(np.concatenate((atributos_fr,atributos_rv),axis=1))\n",
    "\n",
    "# Aplanar X_seq2\n",
    "#a.append(X_combined_flat)\n",
    "#b.append(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14764, 32)\n",
      "(14764,)\n"
     ]
    }
   ],
   "source": [
    "print(x_prueba.shape)\n",
    "print(y_prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14764,)\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_regressor.predict(x_prueba)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14764,)\n"
     ]
    }
   ],
   "source": [
    "print(y_prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.22436336008358926\n",
      "R-squared: 0.014542916798066075\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_prueba, y_pred)\n",
    "r2 = r2_score(y_prueba, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14764,)\n",
      "(14764,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_prueba.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similitudes 9999\n",
      "elementos pre 3027\n",
      "elementos og 5176\n",
      "totales: 14764\n",
      "delta el 2149\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "count1=0\n",
    "count2=0\n",
    "for i,j in zip(y_pred,y_prueba):\n",
    "    if i>0.5:\n",
    "        aux=1\n",
    "    else:\n",
    "        aux=0\n",
    "    if aux==j:\n",
    "        count=count+1\n",
    "    if aux==1:\n",
    "        count1=count1+1\n",
    "    if j==1:\n",
    "        count2=count2+1\n",
    "print(f'similitudes {count}')\n",
    "print(f'elementos pre {count1}')\n",
    "print(f'elementos og {count2}')\n",
    "\n",
    "print(f\"totales: {len(y_prueba)}\")\n",
    "print(f\"delta el {count2-count1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similitudes 9999\n",
    "elementos pre 3027\n",
    "elementos og 5176\n",
    "totales: 14764\n",
    "delta el 2149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similitudes 9417\n",
    "elementos pre 1493\n",
    "elementos og 5176\n",
    "totales: 14764\n",
    "delta el 3683"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cambio de paragdigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similitudes 4718\n",
    "elementos pre 1459\n",
    "elementos og 1620\n",
    "4987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prueba 3 archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17929\n",
    "5342\n",
    "5960\n",
    "18839\n",
    " unos\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17929\n",
    "13497\n",
    "12879\n",
    "18839\n",
    "ceros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1345\n",
    "1046\n",
    "12879\n",
    "18839\n",
    "ceros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1345\n",
    "301\n",
    "5960\n",
    "18839\n",
    "unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
